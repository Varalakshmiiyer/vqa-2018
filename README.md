# Visual Question Answering: May I Have Your Attention Please? 

## Project Overview

[VQA](http://visualqa.org) is a new dataset containing openended questions about images. 
These questions require an understanding of vision,language and commonsense knowledge to answer. 

We experiment with various methods and reproduce them in Py-Torch. We try to analyse the different models presented and also our own model which uses attention. 

In totality we experiment with 7 different models, in a constrained environment of training upto only 10 epochs. 

We explain the models we tried, and the choices we made while creating our own model. 

We additionaly release an extremely lightweight yet modular code which can be used to perform more experiments with no time setting up the framework.

## Project Report
[Project Report](VQA.pdf)

## Contributors:
* [Vibhu Jawa](http://github.com/vibhujawa)
* [Praateek Mahajan](http://prtk.in)
* [Iskandar Atakhodjaev](https://github.com/atah1991)
