{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import word2vec\n",
    "import scipy.signal\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "# If we want proper CUDA debug info.\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['axes.grid'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = \"/Users/jawa/Desktop/mark_ra/falconet/models/resources/\"\n",
    "glove_dim = 100\n",
    "glove_file = \"glove.twitter.27B.{}d.txt\".format(glove_dim)\n",
    "glove2word2vec(glove_input_file=glove_dir+glove_file, word2vec_output_file=\"resources/gensim_glove_vectors.txt\")\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"resources/gensim_glove_vectors.txt\", binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3352e-01,  9.3655e-02, -1.4955e-01,  4.5389e-01, -2.9652e-01,\n",
       "        3.9855e-01,  5.8720e-01,  3.7310e-01,  4.0705e-01,  1.2912e+00,\n",
       "       -2.5254e-01, -3.3421e-01, -4.0356e+00,  5.4054e-01,  3.7914e-01,\n",
       "        6.5204e-01,  2.0346e-01, -3.6562e-01, -6.0288e-01, -5.6573e-01,\n",
       "        4.8248e-01,  6.5377e-02, -2.6782e-01,  8.0191e-02,  1.9383e-01,\n",
       "       -3.8029e-01, -3.9171e-01, -3.4809e-01, -7.1972e-01, -2.3332e-01,\n",
       "       -1.6676e-01,  2.1976e-01,  3.2141e-02, -3.3264e-01, -1.0799e+00,\n",
       "       -2.2029e-01,  2.2205e-01, -1.5094e-01,  2.9377e-01, -1.3618e-01,\n",
       "       -1.0509e+00, -1.0690e-01,  3.6625e-01, -1.4283e-01, -5.7559e-01,\n",
       "       -9.2575e-02, -7.0247e-02, -1.8954e-01, -4.8209e-01,  1.3509e-01,\n",
       "       -4.7616e-01,  2.8590e-01, -4.7091e-01, -2.4828e-01,  5.6715e-01,\n",
       "       -1.9084e-01, -4.1764e-02,  4.5559e-02,  6.8688e-01,  3.4829e-02,\n",
       "        2.9223e-03, -6.9852e-02,  6.0892e-01, -6.0985e-01,  2.4361e-01,\n",
       "       -2.0014e-01, -2.2803e-01,  2.9203e-01, -1.2023e-01, -7.3402e-02,\n",
       "       -3.5904e-01,  6.3710e-01,  1.1236e-01, -8.8206e-01, -4.3355e-01,\n",
       "        1.1865e-02,  2.3696e-01,  5.5449e-01,  2.0004e-01,  2.8420e-01,\n",
       "        1.1491e+00, -5.6616e-02, -5.7219e-01, -7.1170e-01,  2.1808e-01,\n",
       "       -4.7767e-01, -1.3040e-01, -1.0161e-01, -1.4757e-01,  1.6776e-02,\n",
       "       -7.3729e-01,  5.3006e-01, -5.5147e-02,  9.7506e-02, -8.3781e-01,\n",
       "       -4.1032e-01, -2.8769e-01,  3.6642e-01,  4.5031e-01,  4.0651e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model['idk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71940005, -0.16053   , -0.02105001, -0.400193  ,  0.01777002,\n",
       "        0.174238  , -0.27057698, -0.09550999, -0.01642901,  0.38466   ,\n",
       "        0.52881   , -0.07535   , -0.47440004,  0.33339006,  0.28133997,\n",
       "       -0.36134   , -0.05463001,  0.12857   ,  0.66929996, -0.20911801,\n",
       "       -0.13664001, -0.13915   , -0.184277  , -0.72419   ,  0.17056006,\n",
       "        0.02060997, -0.22682999, -0.518969  , -0.31137002, -0.47429   ,\n",
       "       -0.10251001,  0.48950002, -0.339654  , -0.417704  ,  0.404462  ,\n",
       "        0.274409  , -0.19733599, -0.18448   ,  0.26866   , -0.45244998,\n",
       "        0.06341399,  0.35621   , -0.58125997, -0.232124  ,  0.49095   ,\n",
       "       -0.17906001, -0.375117  ,  0.44752002,  0.660368  ,  0.243958  ,\n",
       "       -0.32624   , -0.32801798,  0.160478  ,  0.76563   , -0.79741   ,\n",
       "        0.03702003,  0.403962  , -0.6136    ,  0.573618  , -0.45720997,\n",
       "       -0.01168001, -0.69703996,  0.1785654 , -0.304301  ,  0.11383002,\n",
       "       -0.96731395,  0.58383   , -0.28404   , -0.76435   , -0.443025  ,\n",
       "        0.201228  , -0.50894994,  0.03721002,  0.23189   ,  0.83026004,\n",
       "       -0.13726   , -0.14919999,  0.363736  ,  0.00853001, -0.284604  ,\n",
       "       -0.84203994,  0.4472    , -0.39146   ,  0.26647002, -0.03417999,\n",
       "        0.19819   , -0.42735797, -0.853895  ,  0.33451998,  0.0604048 ,\n",
       "       -0.06825995, -0.41783   , -0.26915   ,  0.29634   ,  0.72660303,\n",
       "        0.601563  , -0.09652801,  0.18298   ,  0.18658   ,  0.665815  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model['king'] - glove_model['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre process model_dir\n",
    "model_dir = \"data/processed/nans,2000_maxlength,26_minwcount,0_nlp,mcb_pad,left_trainsplit,train\"\n",
    "# aid_to_ans.pickle\n",
    "aid_to_ans = pickle.load(open(os.path.join(model_dir,\"aid_to_ans.pickle\"),\"rb\"))\n",
    "# ans_to_aid.pickle\n",
    "ans_to_aid = pickle.load(open(os.path.join(model_dir,\"ans_to_aid.pickle\"),\"rb\"))\n",
    "# testdevset.pickle\n",
    "testdevset = pickle.load(open(os.path.join(model_dir,\"testdevset.pickle\"),\"rb\"))\n",
    "# testset.pickle\n",
    "testset = pickle.load(open(os.path.join(model_dir,\"testset.pickle\"),\"rb\"))\n",
    "# trainset.pickle\n",
    "trainset = pickle.load(open(os.path.join(model_dir,\"trainset.pickle\"),\"rb\"))\n",
    "# valset.pickle\n",
    "valset = pickle.load(open(os.path.join(model_dir,\"valset.pickle\"),\"rb\"))\n",
    "# wid_to_word.pickle\n",
    "wid_to_word = pickle.load(open(os.path.join(model_dir,\"wid_to_word.pickle\"),\"rb\"))\n",
    "# word_to_wid.pickle\n",
    "word_to_wid = pickle.load(open(os.path.join(model_dir,\"word_to_wid.pickle\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'yes',\n",
       " 'answer_aid': 0,\n",
       " 'answers': ['yes'],\n",
       " 'answers_aid': [0],\n",
       " 'answers_count': [10],\n",
       " 'answers_occurence': [['yes', 10]],\n",
       " 'image_name': 'COCO_train2014_000000393221.jpg',\n",
       " 'question': 'Is the sky blue?',\n",
       " 'question_id': 393221000,\n",
       " 'question_length': 4,\n",
       " 'question_wids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  12,\n",
       "  33,\n",
       "  34],\n",
       " 'question_words': ['is', 'the', 'sky', 'blue'],\n",
       " 'question_words_UNK': ['is', 'the', 'sky', 'blue'],\n",
       " 'seq_length': 4}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualQuestionsDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, ds,ans_to_aid,aid_to_ans,wid_to_word,word_to_wid,image_root_dir=None,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.question_answer_ds =  ds\n",
    "        self.ans_to_aid = ans_to_aid\n",
    "        self.aid_to_ans = aid_to_ans\n",
    "        self.wid_to_word = wid_to_word\n",
    "        self.word_to_wid = word_to_wid\n",
    "        self.image_root_dir = image_root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_answer_ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # self.image_root_dir\n",
    "        image_feat = None\n",
    "        \n",
    "        question = self.question_answer_ds[idx]['question_wids']\n",
    "        empty_vec = np\n",
    "        question_vec = [glove_model[wid_to_word[x]] for x in question if x!=0 ]\n",
    "        answer_id = self.question_answer_ds[idx]['answer_aid']\n",
    "        return question_vec,answer_id,image_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "934\n"
     ]
    }
   ],
   "source": [
    "test_dataset = VisualQuestionsDataset(trainset,ans_to_aid,aid_to_ans,wid_to_word,word_to_wid)\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    question,answer,_ = test_dataset[i]\n",
    "    print(len(question))\n",
    "    print(answer)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eff_treat)",
   "language": "python",
   "name": "eff_treat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
